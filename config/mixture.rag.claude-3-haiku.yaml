experiment_name: "mixture-rag-claude-3-haiku-corrected"

layers:
  - layer_type: "rag"
    layer_spec:
      - llm:
          provider: "groq"
          model_spec:
            model_name: "gemma2-9b-it"
            temperature: 0
            max_tokens: 4096
          prompt:
            system_message: | 
              You are an assistant that has a lot of knowledge about Large Language Models.
              Answer the user's question in a way that is easy to understand and informative.
              Use the provided context to generate a response that is relevant and accurate.
            user_message: "Please answer my question based on the provided context:"
      - llm:
          provider: "bedrock"
          model_spec:
            model_id: "mistral.mixtral-8x7b-instruct-v0:1"
            model_kwargs: 
              max_tokens: 4096
              temperature: 0
              top_p: 0
          prompt:
            system_message: | 
              You are an assistant that has a lot of knowledge about Large Language Models.
              Answer the user's question in a way that is easy to understand and informative.
              Use the provided context to generate a response that is relevant and accurate.
            user_message: "Please answer my question based on the provided context:"
      - llm:
          provider: "bedrock"
          model_spec:
              model_id: "meta.llama3-1-8b-instruct-v1:0"
              model_kwargs: 
                max_tokens: 4096
                temperature: 0
                top_p: 0
          prompt:
            system_message: | 
              You are an assistant that has a lot of knowledge about Large Language Models.
              Answer the user's question in a way that is easy to understand and informative.
              Use the provided context to generate a response that is relevant and accurate.
            user_message: "Please answer my question based on the provided context:"
  - layer_type: "aggregator"
    layer_spec:
      - llm:
          provider: "bedrock"
          model_spec:
            model_id: "anthropic.claude-3-haiku-20240307-v1:0"
            model_kwargs:
              max_tokens: 4096
              temperature: 0
              top_p: 0
              stop_sequences: ["\n\nHuman"]
          prompt:
            system_message: |
              You have been provided with a set of responses from various small language models to the latest user query. 
              Your task is to synthesize these responses into a single, high-quality response. 
              It is crucial to critically evaluate the information provided in these responses, recognizing that some of it may be biased or incorrect. 
              Your response should not simply replicate the given answers but should offer a refined, accurate, and comprehensive reply. 
              Ensure your response is well-structured, coherent, and adheres to the highest standards of accuracy and reliability.
            user_message: "Please synthesize the responses from the small language models and give me only the most accurate information."

embedder:
  model_id: "amazon.titan-embed-text-v2:0"
  model_kwargs:
    dimensions: 512
    normalize: true

retriever:
  search_type: "similarity"
  retriever_kwargs:
    k: 5

chunker:
  chunk_size: 1500
  chunk_overlap: 100

data:
  path: "./data"

vector_store:
  path: "./data/database_1500_100"