{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring results data\n",
    "\n",
    "The idea of this notebook is to explore the results data and try to find the best RAG approach by analizing the scores of metrics.\n",
    "\n",
    "For metrics, we are using:\n",
    "- faithfulness\n",
    "- answer_relevancy\n",
    "- context_utilization\n",
    "\n",
    "Each question for each experiment has scores for each metrics. We will try to do some different analysis of the scores to find the best approach:\n",
    "\n",
    "- Average of the scores for each metric on experiment level and then analyzing the results, after that creating a score which is an sum of the average scores and then analyzing the results.\n",
    "- Average scores for each metrics on question level and then analyzing the results, after that we drop the questions with the lowest scores and then analyzing the results based on the first approach.\n",
    "\n",
    "**First steps:**\n",
    "\n",
    "The first steps that need to be done are:\n",
    "- importing the libraries needed for EDA\n",
    "- loading the data\n",
    "- checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the results.csv file\n",
    "dataframe = pd.read_csv(\"/home/bojan/Work/mixture-of-rags/results/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_utilization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>5d7ae2d3-f2b8-4840-b877-69165f991599</td>\n",
       "      <td>How can attention be described in the Transfor...</td>\n",
       "      <td>The response from the second model provides th...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.723033</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>aa2067f5-33f7-4d70-b4c9-f1752084c8ae</td>\n",
       "      <td>What is Mixture of Agents?</td>\n",
       "      <td>The response from the third model provides the...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.466129</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>cefa79c4-cba0-4961-bc87-005e2c2b8837</td>\n",
       "      <td>Is Mixtral based on the idea of a mixture of e...</td>\n",
       "      <td>Based on the provided responses, the best resp...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.636265</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>8f2ee9a4-72d8-4956-8131-fa0ed9bce4a0</td>\n",
       "      <td>What is sliding window attention?</td>\n",
       "      <td>The response from the first model provides the...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.691174</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>584e89e1-cc11-4101-8c96-f10cb725fa15</td>\n",
       "      <td>How many stages are there in the development o...</td>\n",
       "      <td>The response from the second model provides th...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938562</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      experiment_name                              trace_id  \\\n",
       "0  mixture-rag-claude-3-haiku-thought  5d7ae2d3-f2b8-4840-b877-69165f991599   \n",
       "1  mixture-rag-claude-3-haiku-thought  aa2067f5-33f7-4d70-b4c9-f1752084c8ae   \n",
       "2  mixture-rag-claude-3-haiku-thought  cefa79c4-cba0-4961-bc87-005e2c2b8837   \n",
       "3  mixture-rag-claude-3-haiku-thought  8f2ee9a4-72d8-4956-8131-fa0ed9bce4a0   \n",
       "4  mixture-rag-claude-3-haiku-thought  584e89e1-cc11-4101-8c96-f10cb725fa15   \n",
       "\n",
       "                                            question  \\\n",
       "0  How can attention be described in the Transfor...   \n",
       "1                         What is Mixture of Agents?   \n",
       "2  Is Mixtral based on the idea of a mixture of e...   \n",
       "3                  What is sliding window attention?   \n",
       "4  How many stages are there in the development o...   \n",
       "\n",
       "                                              answer  faithfulness  \\\n",
       "0  The response from the second model provides th...      0.727273   \n",
       "1  The response from the third model provides the...      0.555556   \n",
       "2  Based on the provided responses, the best resp...      0.750000   \n",
       "3  The response from the first model provides the...      0.571429   \n",
       "4  The response from the second model provides th...      1.000000   \n",
       "\n",
       "   answer_relevancy  context_utilization  \n",
       "0          0.723033             1.000000  \n",
       "1          0.466129             0.805556  \n",
       "2          0.636265             1.000000  \n",
       "3          0.691174             1.000000  \n",
       "4          0.938562             1.000000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the dataframe\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis based on the first approach\n",
    "\n",
    "The steps for the first approach are:\n",
    "- Create a copy of the data\n",
    "- Calculate the average score for each metrics per question(row)\n",
    "- Check if the scores are created correctly\n",
    "- Create a dataframe with all the metrics + the new score and sort the values by all the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of the dataframe\n",
    "dataframe_1 = dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a score for each row by calculating the mean of the scores for each row (faithfulness, answer_relevancy, context_utilization)\n",
    "dataframe_1[\"score\"] = dataframe_1[\n",
    "    [\"faithfulness\", \"answer_relevancy\", \"context_utilization\"]\n",
    "].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_utilization</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>5d7ae2d3-f2b8-4840-b877-69165f991599</td>\n",
       "      <td>How can attention be described in the Transfor...</td>\n",
       "      <td>The response from the second model provides th...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.723033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>aa2067f5-33f7-4d70-b4c9-f1752084c8ae</td>\n",
       "      <td>What is Mixture of Agents?</td>\n",
       "      <td>The response from the third model provides the...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.466129</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.609080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>cefa79c4-cba0-4961-bc87-005e2c2b8837</td>\n",
       "      <td>Is Mixtral based on the idea of a mixture of e...</td>\n",
       "      <td>Based on the provided responses, the best resp...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.636265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.795422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>8f2ee9a4-72d8-4956-8131-fa0ed9bce4a0</td>\n",
       "      <td>What is sliding window attention?</td>\n",
       "      <td>The response from the first model provides the...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.691174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>584e89e1-cc11-4101-8c96-f10cb725fa15</td>\n",
       "      <td>How many stages are there in the development o...</td>\n",
       "      <td>The response from the second model provides th...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      experiment_name                              trace_id  \\\n",
       "0  mixture-rag-claude-3-haiku-thought  5d7ae2d3-f2b8-4840-b877-69165f991599   \n",
       "1  mixture-rag-claude-3-haiku-thought  aa2067f5-33f7-4d70-b4c9-f1752084c8ae   \n",
       "2  mixture-rag-claude-3-haiku-thought  cefa79c4-cba0-4961-bc87-005e2c2b8837   \n",
       "3  mixture-rag-claude-3-haiku-thought  8f2ee9a4-72d8-4956-8131-fa0ed9bce4a0   \n",
       "4  mixture-rag-claude-3-haiku-thought  584e89e1-cc11-4101-8c96-f10cb725fa15   \n",
       "\n",
       "                                            question  \\\n",
       "0  How can attention be described in the Transfor...   \n",
       "1                         What is Mixture of Agents?   \n",
       "2  Is Mixtral based on the idea of a mixture of e...   \n",
       "3                  What is sliding window attention?   \n",
       "4  How many stages are there in the development o...   \n",
       "\n",
       "                                              answer  faithfulness  \\\n",
       "0  The response from the second model provides th...      0.727273   \n",
       "1  The response from the third model provides the...      0.555556   \n",
       "2  Based on the provided responses, the best resp...      0.750000   \n",
       "3  The response from the first model provides the...      0.571429   \n",
       "4  The response from the second model provides th...      1.000000   \n",
       "\n",
       "   answer_relevancy  context_utilization     score  \n",
       "0          0.723033             1.000000  0.816768  \n",
       "1          0.466129             0.805556  0.609080  \n",
       "2          0.636265             1.000000  0.795422  \n",
       "3          0.691174             1.000000  0.754201  \n",
       "4          0.938562             1.000000  0.979521  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the new dataframe\n",
    "dataframe_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the dataframe by experiment_name and calculating the mean of the scores for each experiment\n",
    "dataframe_1_mean = (\n",
    "    dataframe_1.drop(columns=[\"trace_id\", \"question\", \"answer\"])\n",
    "    .groupby(\"experiment_name\")\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_utilization</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-8b</th>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.792426</td>\n",
       "      <td>0.781746</td>\n",
       "      <td>0.832132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-405b-instruct</th>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.841026</td>\n",
       "      <td>0.807540</td>\n",
       "      <td>0.851443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-70b-instruct</th>\n",
       "      <td>0.903128</td>\n",
       "      <td>0.839752</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.849478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-8b</th>\n",
       "      <td>0.887117</td>\n",
       "      <td>0.808932</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.835191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma-7b-it</th>\n",
       "      <td>0.873460</td>\n",
       "      <td>0.834710</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.833279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o</th>\n",
       "      <td>0.873352</td>\n",
       "      <td>0.852122</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.850290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-thought</th>\n",
       "      <td>0.864067</td>\n",
       "      <td>0.857216</td>\n",
       "      <td>0.799603</td>\n",
       "      <td>0.840295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-opus</th>\n",
       "      <td>0.836947</td>\n",
       "      <td>0.860946</td>\n",
       "      <td>0.718254</td>\n",
       "      <td>0.805382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mixtral-8x7b-instruct</th>\n",
       "      <td>0.835374</td>\n",
       "      <td>0.781165</td>\n",
       "      <td>0.837302</td>\n",
       "      <td>0.817947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-70b</th>\n",
       "      <td>0.817743</td>\n",
       "      <td>0.865189</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>0.822221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-thought</th>\n",
       "      <td>0.816186</td>\n",
       "      <td>0.834754</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.805604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma2-9b-it</th>\n",
       "      <td>0.814856</td>\n",
       "      <td>0.888774</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>0.829120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-modified</th>\n",
       "      <td>0.800564</td>\n",
       "      <td>0.831477</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.807241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-thought</th>\n",
       "      <td>0.799012</td>\n",
       "      <td>0.801560</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.787492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mistral-7b-instruct</th>\n",
       "      <td>0.798987</td>\n",
       "      <td>0.847659</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.822030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3.5-sonnet</th>\n",
       "      <td>0.798158</td>\n",
       "      <td>0.870635</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.814201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o-mini</th>\n",
       "      <td>0.780492</td>\n",
       "      <td>0.885133</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.826372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-sonnet</th>\n",
       "      <td>0.777853</td>\n",
       "      <td>0.827206</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.790311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-modified</th>\n",
       "      <td>0.768318</td>\n",
       "      <td>0.819483</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.800431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-haiku</th>\n",
       "      <td>0.748164</td>\n",
       "      <td>0.821864</td>\n",
       "      <td>0.759921</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4-turbo</th>\n",
       "      <td>0.744952</td>\n",
       "      <td>0.847259</td>\n",
       "      <td>0.771825</td>\n",
       "      <td>0.788012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct</th>\n",
       "      <td>0.710796</td>\n",
       "      <td>0.776089</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.763485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct</th>\n",
       "      <td>0.702459</td>\n",
       "      <td>0.795491</td>\n",
       "      <td>0.823413</td>\n",
       "      <td>0.773787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it</th>\n",
       "      <td>0.666729</td>\n",
       "      <td>0.821013</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.760464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-modified</th>\n",
       "      <td>0.661541</td>\n",
       "      <td>0.843879</td>\n",
       "      <td>0.811508</td>\n",
       "      <td>0.772309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-modified</th>\n",
       "      <td>0.629421</td>\n",
       "      <td>0.834074</td>\n",
       "      <td>0.744048</td>\n",
       "      <td>0.735848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku</th>\n",
       "      <td>0.610196</td>\n",
       "      <td>0.820688</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.741512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-thought</th>\n",
       "      <td>0.605463</td>\n",
       "      <td>0.731066</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.688896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           faithfulness  answer_relevancy  \\\n",
       "experiment_name                                                             \n",
       "simple-rag-llama-3.1-8b                        0.922222          0.792426   \n",
       "simple-rag-llama-3.1-405b-instruct             0.905762          0.841026   \n",
       "simple-rag-llama-3.1-70b-instruct              0.903128          0.839752   \n",
       "simple-rag-llama-3-8b                          0.887117          0.808932   \n",
       "simple-rag-gemma-7b-it                         0.873460          0.834710   \n",
       "simple-rag-gpt-4o                              0.873352          0.852122   \n",
       "mixture-rag-gemma2-9b-it-thought               0.864067          0.857216   \n",
       "simple-rag-claude-3-opus                       0.836947          0.860946   \n",
       "simple-rag-mixtral-8x7b-instruct               0.835374          0.781165   \n",
       "simple-rag-llama-3-70b                         0.817743          0.865189   \n",
       "mixture-rag-llama3.1-8b-instruct-thought       0.816186          0.834754   \n",
       "simple-rag-gemma2-9b-it                        0.814856          0.888774   \n",
       "mixture-rag-mixtral-8x7-instruct-modified      0.800564          0.831477   \n",
       "mixture-rag-mixtral-8x7-instruct-thought       0.799012          0.801560   \n",
       "simple-rag-mistral-7b-instruct                 0.798987          0.847659   \n",
       "simple-rag-claude-3.5-sonnet                   0.798158          0.870635   \n",
       "simple-rag-gpt-4o-mini                         0.780492          0.885133   \n",
       "simple-rag-claude-3-sonnet                     0.777853          0.827206   \n",
       "mixture-rag-gemma2-9b-it-modified              0.768318          0.819483   \n",
       "simple-rag-claude-3-haiku                      0.748164          0.821864   \n",
       "simple-rag-gpt-4-turbo                         0.744952          0.847259   \n",
       "mixture-rag-llama3.1-8b-instruct               0.710796          0.776089   \n",
       "mixture-rag-mixtral-8x7-instruct               0.702459          0.795491   \n",
       "mixture-rag-gemma2-9b-it                       0.666729          0.821013   \n",
       "mixture-rag-llama3.1-8b-instruct-modified      0.661541          0.843879   \n",
       "mixture-rag-claude-3-haiku-modified            0.629421          0.834074   \n",
       "mixture-rag-claude-3-haiku                     0.610196          0.820688   \n",
       "mixture-rag-claude-3-haiku-thought             0.605463          0.731066   \n",
       "\n",
       "                                           context_utilization     score  \n",
       "experiment_name                                                           \n",
       "simple-rag-llama-3.1-8b                               0.781746  0.832132  \n",
       "simple-rag-llama-3.1-405b-instruct                    0.807540  0.851443  \n",
       "simple-rag-llama-3.1-70b-instruct                     0.805556  0.849478  \n",
       "simple-rag-llama-3-8b                                 0.809524  0.835191  \n",
       "simple-rag-gemma-7b-it                                0.791667  0.833279  \n",
       "simple-rag-gpt-4o                                     0.825397  0.850290  \n",
       "mixture-rag-gemma2-9b-it-thought                      0.799603  0.840295  \n",
       "simple-rag-claude-3-opus                              0.718254  0.805382  \n",
       "simple-rag-mixtral-8x7b-instruct                      0.837302  0.817947  \n",
       "simple-rag-llama-3-70b                                0.783730  0.822221  \n",
       "mixture-rag-llama3.1-8b-instruct-thought              0.765873  0.805604  \n",
       "simple-rag-gemma2-9b-it                               0.783730  0.829120  \n",
       "mixture-rag-mixtral-8x7-instruct-modified             0.789683  0.807241  \n",
       "mixture-rag-mixtral-8x7-instruct-thought              0.761905  0.787492  \n",
       "simple-rag-mistral-7b-instruct                        0.819444  0.822030  \n",
       "simple-rag-claude-3.5-sonnet                          0.773810  0.814201  \n",
       "simple-rag-gpt-4o-mini                                0.813492  0.826372  \n",
       "simple-rag-claude-3-sonnet                            0.765873  0.790311  \n",
       "mixture-rag-gemma2-9b-it-modified                     0.813492  0.800431  \n",
       "simple-rag-claude-3-haiku                             0.759921  0.776649  \n",
       "simple-rag-gpt-4-turbo                                0.771825  0.788012  \n",
       "mixture-rag-llama3.1-8b-instruct                      0.803571  0.763485  \n",
       "mixture-rag-mixtral-8x7-instruct                      0.823413  0.773787  \n",
       "mixture-rag-gemma2-9b-it                              0.793651  0.760464  \n",
       "mixture-rag-llama3.1-8b-instruct-modified             0.811508  0.772309  \n",
       "mixture-rag-claude-3-haiku-modified                   0.744048  0.735848  \n",
       "mixture-rag-claude-3-haiku                            0.793651  0.741512  \n",
       "mixture-rag-claude-3-haiku-thought                    0.730159  0.688896  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the dataframe sorted by faithfulness by descending order\n",
    "dataframe_1_mean.sort_values(by=\"faithfulness\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_utilization</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma2-9b-it</th>\n",
       "      <td>0.814856</td>\n",
       "      <td>0.888774</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>0.829120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o-mini</th>\n",
       "      <td>0.780492</td>\n",
       "      <td>0.885133</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.826372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3.5-sonnet</th>\n",
       "      <td>0.798158</td>\n",
       "      <td>0.870635</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.814201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-70b</th>\n",
       "      <td>0.817743</td>\n",
       "      <td>0.865189</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>0.822221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-opus</th>\n",
       "      <td>0.836947</td>\n",
       "      <td>0.860946</td>\n",
       "      <td>0.718254</td>\n",
       "      <td>0.805382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-thought</th>\n",
       "      <td>0.864067</td>\n",
       "      <td>0.857216</td>\n",
       "      <td>0.799603</td>\n",
       "      <td>0.840295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o</th>\n",
       "      <td>0.873352</td>\n",
       "      <td>0.852122</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.850290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mistral-7b-instruct</th>\n",
       "      <td>0.798987</td>\n",
       "      <td>0.847659</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.822030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4-turbo</th>\n",
       "      <td>0.744952</td>\n",
       "      <td>0.847259</td>\n",
       "      <td>0.771825</td>\n",
       "      <td>0.788012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-modified</th>\n",
       "      <td>0.661541</td>\n",
       "      <td>0.843879</td>\n",
       "      <td>0.811508</td>\n",
       "      <td>0.772309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-405b-instruct</th>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.841026</td>\n",
       "      <td>0.807540</td>\n",
       "      <td>0.851443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-70b-instruct</th>\n",
       "      <td>0.903128</td>\n",
       "      <td>0.839752</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.849478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-thought</th>\n",
       "      <td>0.816186</td>\n",
       "      <td>0.834754</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.805604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma-7b-it</th>\n",
       "      <td>0.873460</td>\n",
       "      <td>0.834710</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.833279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-modified</th>\n",
       "      <td>0.629421</td>\n",
       "      <td>0.834074</td>\n",
       "      <td>0.744048</td>\n",
       "      <td>0.735848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-modified</th>\n",
       "      <td>0.800564</td>\n",
       "      <td>0.831477</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.807241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-sonnet</th>\n",
       "      <td>0.777853</td>\n",
       "      <td>0.827206</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.790311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-haiku</th>\n",
       "      <td>0.748164</td>\n",
       "      <td>0.821864</td>\n",
       "      <td>0.759921</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it</th>\n",
       "      <td>0.666729</td>\n",
       "      <td>0.821013</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.760464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku</th>\n",
       "      <td>0.610196</td>\n",
       "      <td>0.820688</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.741512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-modified</th>\n",
       "      <td>0.768318</td>\n",
       "      <td>0.819483</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.800431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-8b</th>\n",
       "      <td>0.887117</td>\n",
       "      <td>0.808932</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.835191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-thought</th>\n",
       "      <td>0.799012</td>\n",
       "      <td>0.801560</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.787492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct</th>\n",
       "      <td>0.702459</td>\n",
       "      <td>0.795491</td>\n",
       "      <td>0.823413</td>\n",
       "      <td>0.773787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-8b</th>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.792426</td>\n",
       "      <td>0.781746</td>\n",
       "      <td>0.832132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mixtral-8x7b-instruct</th>\n",
       "      <td>0.835374</td>\n",
       "      <td>0.781165</td>\n",
       "      <td>0.837302</td>\n",
       "      <td>0.817947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct</th>\n",
       "      <td>0.710796</td>\n",
       "      <td>0.776089</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.763485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-thought</th>\n",
       "      <td>0.605463</td>\n",
       "      <td>0.731066</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.688896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           faithfulness  answer_relevancy  \\\n",
       "experiment_name                                                             \n",
       "simple-rag-gemma2-9b-it                        0.814856          0.888774   \n",
       "simple-rag-gpt-4o-mini                         0.780492          0.885133   \n",
       "simple-rag-claude-3.5-sonnet                   0.798158          0.870635   \n",
       "simple-rag-llama-3-70b                         0.817743          0.865189   \n",
       "simple-rag-claude-3-opus                       0.836947          0.860946   \n",
       "mixture-rag-gemma2-9b-it-thought               0.864067          0.857216   \n",
       "simple-rag-gpt-4o                              0.873352          0.852122   \n",
       "simple-rag-mistral-7b-instruct                 0.798987          0.847659   \n",
       "simple-rag-gpt-4-turbo                         0.744952          0.847259   \n",
       "mixture-rag-llama3.1-8b-instruct-modified      0.661541          0.843879   \n",
       "simple-rag-llama-3.1-405b-instruct             0.905762          0.841026   \n",
       "simple-rag-llama-3.1-70b-instruct              0.903128          0.839752   \n",
       "mixture-rag-llama3.1-8b-instruct-thought       0.816186          0.834754   \n",
       "simple-rag-gemma-7b-it                         0.873460          0.834710   \n",
       "mixture-rag-claude-3-haiku-modified            0.629421          0.834074   \n",
       "mixture-rag-mixtral-8x7-instruct-modified      0.800564          0.831477   \n",
       "simple-rag-claude-3-sonnet                     0.777853          0.827206   \n",
       "simple-rag-claude-3-haiku                      0.748164          0.821864   \n",
       "mixture-rag-gemma2-9b-it                       0.666729          0.821013   \n",
       "mixture-rag-claude-3-haiku                     0.610196          0.820688   \n",
       "mixture-rag-gemma2-9b-it-modified              0.768318          0.819483   \n",
       "simple-rag-llama-3-8b                          0.887117          0.808932   \n",
       "mixture-rag-mixtral-8x7-instruct-thought       0.799012          0.801560   \n",
       "mixture-rag-mixtral-8x7-instruct               0.702459          0.795491   \n",
       "simple-rag-llama-3.1-8b                        0.922222          0.792426   \n",
       "simple-rag-mixtral-8x7b-instruct               0.835374          0.781165   \n",
       "mixture-rag-llama3.1-8b-instruct               0.710796          0.776089   \n",
       "mixture-rag-claude-3-haiku-thought             0.605463          0.731066   \n",
       "\n",
       "                                           context_utilization     score  \n",
       "experiment_name                                                           \n",
       "simple-rag-gemma2-9b-it                               0.783730  0.829120  \n",
       "simple-rag-gpt-4o-mini                                0.813492  0.826372  \n",
       "simple-rag-claude-3.5-sonnet                          0.773810  0.814201  \n",
       "simple-rag-llama-3-70b                                0.783730  0.822221  \n",
       "simple-rag-claude-3-opus                              0.718254  0.805382  \n",
       "mixture-rag-gemma2-9b-it-thought                      0.799603  0.840295  \n",
       "simple-rag-gpt-4o                                     0.825397  0.850290  \n",
       "simple-rag-mistral-7b-instruct                        0.819444  0.822030  \n",
       "simple-rag-gpt-4-turbo                                0.771825  0.788012  \n",
       "mixture-rag-llama3.1-8b-instruct-modified             0.811508  0.772309  \n",
       "simple-rag-llama-3.1-405b-instruct                    0.807540  0.851443  \n",
       "simple-rag-llama-3.1-70b-instruct                     0.805556  0.849478  \n",
       "mixture-rag-llama3.1-8b-instruct-thought              0.765873  0.805604  \n",
       "simple-rag-gemma-7b-it                                0.791667  0.833279  \n",
       "mixture-rag-claude-3-haiku-modified                   0.744048  0.735848  \n",
       "mixture-rag-mixtral-8x7-instruct-modified             0.789683  0.807241  \n",
       "simple-rag-claude-3-sonnet                            0.765873  0.790311  \n",
       "simple-rag-claude-3-haiku                             0.759921  0.776649  \n",
       "mixture-rag-gemma2-9b-it                              0.793651  0.760464  \n",
       "mixture-rag-claude-3-haiku                            0.793651  0.741512  \n",
       "mixture-rag-gemma2-9b-it-modified                     0.813492  0.800431  \n",
       "simple-rag-llama-3-8b                                 0.809524  0.835191  \n",
       "mixture-rag-mixtral-8x7-instruct-thought              0.761905  0.787492  \n",
       "mixture-rag-mixtral-8x7-instruct                      0.823413  0.773787  \n",
       "simple-rag-llama-3.1-8b                               0.781746  0.832132  \n",
       "simple-rag-mixtral-8x7b-instruct                      0.837302  0.817947  \n",
       "mixture-rag-llama3.1-8b-instruct                      0.803571  0.763485  \n",
       "mixture-rag-claude-3-haiku-thought                    0.730159  0.688896  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the dataframe sorted by answer_relevancy by descending order\n",
    "dataframe_1_mean.sort_values(by=\"answer_relevancy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_utilization</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple-rag-mixtral-8x7b-instruct</th>\n",
       "      <td>0.835374</td>\n",
       "      <td>0.781165</td>\n",
       "      <td>0.837302</td>\n",
       "      <td>0.817947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o</th>\n",
       "      <td>0.873352</td>\n",
       "      <td>0.852122</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.850290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct</th>\n",
       "      <td>0.702459</td>\n",
       "      <td>0.795491</td>\n",
       "      <td>0.823413</td>\n",
       "      <td>0.773787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mistral-7b-instruct</th>\n",
       "      <td>0.798987</td>\n",
       "      <td>0.847659</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.822030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o-mini</th>\n",
       "      <td>0.780492</td>\n",
       "      <td>0.885133</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.826372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-modified</th>\n",
       "      <td>0.768318</td>\n",
       "      <td>0.819483</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.800431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-modified</th>\n",
       "      <td>0.661541</td>\n",
       "      <td>0.843879</td>\n",
       "      <td>0.811508</td>\n",
       "      <td>0.772309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-8b</th>\n",
       "      <td>0.887117</td>\n",
       "      <td>0.808932</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.835191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-405b-instruct</th>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.841026</td>\n",
       "      <td>0.807540</td>\n",
       "      <td>0.851443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-70b-instruct</th>\n",
       "      <td>0.903128</td>\n",
       "      <td>0.839752</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.849478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct</th>\n",
       "      <td>0.710796</td>\n",
       "      <td>0.776089</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.763485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-thought</th>\n",
       "      <td>0.864067</td>\n",
       "      <td>0.857216</td>\n",
       "      <td>0.799603</td>\n",
       "      <td>0.840295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku</th>\n",
       "      <td>0.610196</td>\n",
       "      <td>0.820688</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.741512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it</th>\n",
       "      <td>0.666729</td>\n",
       "      <td>0.821013</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.760464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma-7b-it</th>\n",
       "      <td>0.873460</td>\n",
       "      <td>0.834710</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.833279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-modified</th>\n",
       "      <td>0.800564</td>\n",
       "      <td>0.831477</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.807241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-70b</th>\n",
       "      <td>0.817743</td>\n",
       "      <td>0.865189</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>0.822221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma2-9b-it</th>\n",
       "      <td>0.814856</td>\n",
       "      <td>0.888774</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>0.829120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-8b</th>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.792426</td>\n",
       "      <td>0.781746</td>\n",
       "      <td>0.832132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3.5-sonnet</th>\n",
       "      <td>0.798158</td>\n",
       "      <td>0.870635</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.814201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4-turbo</th>\n",
       "      <td>0.744952</td>\n",
       "      <td>0.847259</td>\n",
       "      <td>0.771825</td>\n",
       "      <td>0.788012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-thought</th>\n",
       "      <td>0.816186</td>\n",
       "      <td>0.834754</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.805604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-sonnet</th>\n",
       "      <td>0.777853</td>\n",
       "      <td>0.827206</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.790311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-thought</th>\n",
       "      <td>0.799012</td>\n",
       "      <td>0.801560</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.787492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-haiku</th>\n",
       "      <td>0.748164</td>\n",
       "      <td>0.821864</td>\n",
       "      <td>0.759921</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-modified</th>\n",
       "      <td>0.629421</td>\n",
       "      <td>0.834074</td>\n",
       "      <td>0.744048</td>\n",
       "      <td>0.735848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-thought</th>\n",
       "      <td>0.605463</td>\n",
       "      <td>0.731066</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.688896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-opus</th>\n",
       "      <td>0.836947</td>\n",
       "      <td>0.860946</td>\n",
       "      <td>0.718254</td>\n",
       "      <td>0.805382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           faithfulness  answer_relevancy  \\\n",
       "experiment_name                                                             \n",
       "simple-rag-mixtral-8x7b-instruct               0.835374          0.781165   \n",
       "simple-rag-gpt-4o                              0.873352          0.852122   \n",
       "mixture-rag-mixtral-8x7-instruct               0.702459          0.795491   \n",
       "simple-rag-mistral-7b-instruct                 0.798987          0.847659   \n",
       "simple-rag-gpt-4o-mini                         0.780492          0.885133   \n",
       "mixture-rag-gemma2-9b-it-modified              0.768318          0.819483   \n",
       "mixture-rag-llama3.1-8b-instruct-modified      0.661541          0.843879   \n",
       "simple-rag-llama-3-8b                          0.887117          0.808932   \n",
       "simple-rag-llama-3.1-405b-instruct             0.905762          0.841026   \n",
       "simple-rag-llama-3.1-70b-instruct              0.903128          0.839752   \n",
       "mixture-rag-llama3.1-8b-instruct               0.710796          0.776089   \n",
       "mixture-rag-gemma2-9b-it-thought               0.864067          0.857216   \n",
       "mixture-rag-claude-3-haiku                     0.610196          0.820688   \n",
       "mixture-rag-gemma2-9b-it                       0.666729          0.821013   \n",
       "simple-rag-gemma-7b-it                         0.873460          0.834710   \n",
       "mixture-rag-mixtral-8x7-instruct-modified      0.800564          0.831477   \n",
       "simple-rag-llama-3-70b                         0.817743          0.865189   \n",
       "simple-rag-gemma2-9b-it                        0.814856          0.888774   \n",
       "simple-rag-llama-3.1-8b                        0.922222          0.792426   \n",
       "simple-rag-claude-3.5-sonnet                   0.798158          0.870635   \n",
       "simple-rag-gpt-4-turbo                         0.744952          0.847259   \n",
       "mixture-rag-llama3.1-8b-instruct-thought       0.816186          0.834754   \n",
       "simple-rag-claude-3-sonnet                     0.777853          0.827206   \n",
       "mixture-rag-mixtral-8x7-instruct-thought       0.799012          0.801560   \n",
       "simple-rag-claude-3-haiku                      0.748164          0.821864   \n",
       "mixture-rag-claude-3-haiku-modified            0.629421          0.834074   \n",
       "mixture-rag-claude-3-haiku-thought             0.605463          0.731066   \n",
       "simple-rag-claude-3-opus                       0.836947          0.860946   \n",
       "\n",
       "                                           context_utilization     score  \n",
       "experiment_name                                                           \n",
       "simple-rag-mixtral-8x7b-instruct                      0.837302  0.817947  \n",
       "simple-rag-gpt-4o                                     0.825397  0.850290  \n",
       "mixture-rag-mixtral-8x7-instruct                      0.823413  0.773787  \n",
       "simple-rag-mistral-7b-instruct                        0.819444  0.822030  \n",
       "simple-rag-gpt-4o-mini                                0.813492  0.826372  \n",
       "mixture-rag-gemma2-9b-it-modified                     0.813492  0.800431  \n",
       "mixture-rag-llama3.1-8b-instruct-modified             0.811508  0.772309  \n",
       "simple-rag-llama-3-8b                                 0.809524  0.835191  \n",
       "simple-rag-llama-3.1-405b-instruct                    0.807540  0.851443  \n",
       "simple-rag-llama-3.1-70b-instruct                     0.805556  0.849478  \n",
       "mixture-rag-llama3.1-8b-instruct                      0.803571  0.763485  \n",
       "mixture-rag-gemma2-9b-it-thought                      0.799603  0.840295  \n",
       "mixture-rag-claude-3-haiku                            0.793651  0.741512  \n",
       "mixture-rag-gemma2-9b-it                              0.793651  0.760464  \n",
       "simple-rag-gemma-7b-it                                0.791667  0.833279  \n",
       "mixture-rag-mixtral-8x7-instruct-modified             0.789683  0.807241  \n",
       "simple-rag-llama-3-70b                                0.783730  0.822221  \n",
       "simple-rag-gemma2-9b-it                               0.783730  0.829120  \n",
       "simple-rag-llama-3.1-8b                               0.781746  0.832132  \n",
       "simple-rag-claude-3.5-sonnet                          0.773810  0.814201  \n",
       "simple-rag-gpt-4-turbo                                0.771825  0.788012  \n",
       "mixture-rag-llama3.1-8b-instruct-thought              0.765873  0.805604  \n",
       "simple-rag-claude-3-sonnet                            0.765873  0.790311  \n",
       "mixture-rag-mixtral-8x7-instruct-thought              0.761905  0.787492  \n",
       "simple-rag-claude-3-haiku                             0.759921  0.776649  \n",
       "mixture-rag-claude-3-haiku-modified                   0.744048  0.735848  \n",
       "mixture-rag-claude-3-haiku-thought                    0.730159  0.688896  \n",
       "simple-rag-claude-3-opus                              0.718254  0.805382  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the dataframe sorted by context_utilization by descending order\n",
    "dataframe_1_mean.sort_values(by=\"context_utilization\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_utilization</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-405b-instruct</th>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.841026</td>\n",
       "      <td>0.807540</td>\n",
       "      <td>0.851443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o</th>\n",
       "      <td>0.873352</td>\n",
       "      <td>0.852122</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.850290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-70b-instruct</th>\n",
       "      <td>0.903128</td>\n",
       "      <td>0.839752</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.849478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-thought</th>\n",
       "      <td>0.864067</td>\n",
       "      <td>0.857216</td>\n",
       "      <td>0.799603</td>\n",
       "      <td>0.840295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-8b</th>\n",
       "      <td>0.887117</td>\n",
       "      <td>0.808932</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.835191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma-7b-it</th>\n",
       "      <td>0.873460</td>\n",
       "      <td>0.834710</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.833279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-8b</th>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.792426</td>\n",
       "      <td>0.781746</td>\n",
       "      <td>0.832132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma2-9b-it</th>\n",
       "      <td>0.814856</td>\n",
       "      <td>0.888774</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>0.829120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o-mini</th>\n",
       "      <td>0.780492</td>\n",
       "      <td>0.885133</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.826372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-70b</th>\n",
       "      <td>0.817743</td>\n",
       "      <td>0.865189</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>0.822221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mistral-7b-instruct</th>\n",
       "      <td>0.798987</td>\n",
       "      <td>0.847659</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.822030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mixtral-8x7b-instruct</th>\n",
       "      <td>0.835374</td>\n",
       "      <td>0.781165</td>\n",
       "      <td>0.837302</td>\n",
       "      <td>0.817947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3.5-sonnet</th>\n",
       "      <td>0.798158</td>\n",
       "      <td>0.870635</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.814201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-modified</th>\n",
       "      <td>0.800564</td>\n",
       "      <td>0.831477</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.807241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-thought</th>\n",
       "      <td>0.816186</td>\n",
       "      <td>0.834754</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.805604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-opus</th>\n",
       "      <td>0.836947</td>\n",
       "      <td>0.860946</td>\n",
       "      <td>0.718254</td>\n",
       "      <td>0.805382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-modified</th>\n",
       "      <td>0.768318</td>\n",
       "      <td>0.819483</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.800431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-sonnet</th>\n",
       "      <td>0.777853</td>\n",
       "      <td>0.827206</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.790311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4-turbo</th>\n",
       "      <td>0.744952</td>\n",
       "      <td>0.847259</td>\n",
       "      <td>0.771825</td>\n",
       "      <td>0.788012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-thought</th>\n",
       "      <td>0.799012</td>\n",
       "      <td>0.801560</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.787492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-haiku</th>\n",
       "      <td>0.748164</td>\n",
       "      <td>0.821864</td>\n",
       "      <td>0.759921</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct</th>\n",
       "      <td>0.702459</td>\n",
       "      <td>0.795491</td>\n",
       "      <td>0.823413</td>\n",
       "      <td>0.773787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-modified</th>\n",
       "      <td>0.661541</td>\n",
       "      <td>0.843879</td>\n",
       "      <td>0.811508</td>\n",
       "      <td>0.772309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct</th>\n",
       "      <td>0.710796</td>\n",
       "      <td>0.776089</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.763485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it</th>\n",
       "      <td>0.666729</td>\n",
       "      <td>0.821013</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.760464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku</th>\n",
       "      <td>0.610196</td>\n",
       "      <td>0.820688</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.741512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-modified</th>\n",
       "      <td>0.629421</td>\n",
       "      <td>0.834074</td>\n",
       "      <td>0.744048</td>\n",
       "      <td>0.735848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-thought</th>\n",
       "      <td>0.605463</td>\n",
       "      <td>0.731066</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.688896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           faithfulness  answer_relevancy  \\\n",
       "experiment_name                                                             \n",
       "simple-rag-llama-3.1-405b-instruct             0.905762          0.841026   \n",
       "simple-rag-gpt-4o                              0.873352          0.852122   \n",
       "simple-rag-llama-3.1-70b-instruct              0.903128          0.839752   \n",
       "mixture-rag-gemma2-9b-it-thought               0.864067          0.857216   \n",
       "simple-rag-llama-3-8b                          0.887117          0.808932   \n",
       "simple-rag-gemma-7b-it                         0.873460          0.834710   \n",
       "simple-rag-llama-3.1-8b                        0.922222          0.792426   \n",
       "simple-rag-gemma2-9b-it                        0.814856          0.888774   \n",
       "simple-rag-gpt-4o-mini                         0.780492          0.885133   \n",
       "simple-rag-llama-3-70b                         0.817743          0.865189   \n",
       "simple-rag-mistral-7b-instruct                 0.798987          0.847659   \n",
       "simple-rag-mixtral-8x7b-instruct               0.835374          0.781165   \n",
       "simple-rag-claude-3.5-sonnet                   0.798158          0.870635   \n",
       "mixture-rag-mixtral-8x7-instruct-modified      0.800564          0.831477   \n",
       "mixture-rag-llama3.1-8b-instruct-thought       0.816186          0.834754   \n",
       "simple-rag-claude-3-opus                       0.836947          0.860946   \n",
       "mixture-rag-gemma2-9b-it-modified              0.768318          0.819483   \n",
       "simple-rag-claude-3-sonnet                     0.777853          0.827206   \n",
       "simple-rag-gpt-4-turbo                         0.744952          0.847259   \n",
       "mixture-rag-mixtral-8x7-instruct-thought       0.799012          0.801560   \n",
       "simple-rag-claude-3-haiku                      0.748164          0.821864   \n",
       "mixture-rag-mixtral-8x7-instruct               0.702459          0.795491   \n",
       "mixture-rag-llama3.1-8b-instruct-modified      0.661541          0.843879   \n",
       "mixture-rag-llama3.1-8b-instruct               0.710796          0.776089   \n",
       "mixture-rag-gemma2-9b-it                       0.666729          0.821013   \n",
       "mixture-rag-claude-3-haiku                     0.610196          0.820688   \n",
       "mixture-rag-claude-3-haiku-modified            0.629421          0.834074   \n",
       "mixture-rag-claude-3-haiku-thought             0.605463          0.731066   \n",
       "\n",
       "                                           context_utilization     score  \n",
       "experiment_name                                                           \n",
       "simple-rag-llama-3.1-405b-instruct                    0.807540  0.851443  \n",
       "simple-rag-gpt-4o                                     0.825397  0.850290  \n",
       "simple-rag-llama-3.1-70b-instruct                     0.805556  0.849478  \n",
       "mixture-rag-gemma2-9b-it-thought                      0.799603  0.840295  \n",
       "simple-rag-llama-3-8b                                 0.809524  0.835191  \n",
       "simple-rag-gemma-7b-it                                0.791667  0.833279  \n",
       "simple-rag-llama-3.1-8b                               0.781746  0.832132  \n",
       "simple-rag-gemma2-9b-it                               0.783730  0.829120  \n",
       "simple-rag-gpt-4o-mini                                0.813492  0.826372  \n",
       "simple-rag-llama-3-70b                                0.783730  0.822221  \n",
       "simple-rag-mistral-7b-instruct                        0.819444  0.822030  \n",
       "simple-rag-mixtral-8x7b-instruct                      0.837302  0.817947  \n",
       "simple-rag-claude-3.5-sonnet                          0.773810  0.814201  \n",
       "mixture-rag-mixtral-8x7-instruct-modified             0.789683  0.807241  \n",
       "mixture-rag-llama3.1-8b-instruct-thought              0.765873  0.805604  \n",
       "simple-rag-claude-3-opus                              0.718254  0.805382  \n",
       "mixture-rag-gemma2-9b-it-modified                     0.813492  0.800431  \n",
       "simple-rag-claude-3-sonnet                            0.765873  0.790311  \n",
       "simple-rag-gpt-4-turbo                                0.771825  0.788012  \n",
       "mixture-rag-mixtral-8x7-instruct-thought              0.761905  0.787492  \n",
       "simple-rag-claude-3-haiku                             0.759921  0.776649  \n",
       "mixture-rag-mixtral-8x7-instruct                      0.823413  0.773787  \n",
       "mixture-rag-llama3.1-8b-instruct-modified             0.811508  0.772309  \n",
       "mixture-rag-llama3.1-8b-instruct                      0.803571  0.763485  \n",
       "mixture-rag-gemma2-9b-it                              0.793651  0.760464  \n",
       "mixture-rag-claude-3-haiku                            0.793651  0.741512  \n",
       "mixture-rag-claude-3-haiku-modified                   0.744048  0.735848  \n",
       "mixture-rag-claude-3-haiku-thought                    0.730159  0.688896  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the dataframe sorted by score(mean of all the metric scores on experiment level) by descending order\n",
    "dataframe_1_mean.sort_values(by=\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis based on the second approach\n",
    "\n",
    "The steps for the second approach are:\n",
    "- Create a copy of the data\n",
    "- Calculate the average score for each metrics per question(row)\n",
    "- Check if the scores are created correctly\n",
    "- Group the scores by question and calculate the average score for each question\n",
    "- Drop the 4 questions with the lowest scores\n",
    "- Do the same steps as in the first approach with the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of the dataframe\n",
    "dataframe_2 = dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a score for each row by calculating the mean of the scores for each row (faithfulness, answer_relevancy, context_utilization)\n",
    "dataframe_2[\"score\"] = dataframe_2[\n",
    "    [\"faithfulness\", \"answer_relevancy\", \"context_utilization\"]\n",
    "].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_utilization</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>5d7ae2d3-f2b8-4840-b877-69165f991599</td>\n",
       "      <td>How can attention be described in the Transfor...</td>\n",
       "      <td>The response from the second model provides th...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.723033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>aa2067f5-33f7-4d70-b4c9-f1752084c8ae</td>\n",
       "      <td>What is Mixture of Agents?</td>\n",
       "      <td>The response from the third model provides the...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.466129</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.609080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>cefa79c4-cba0-4961-bc87-005e2c2b8837</td>\n",
       "      <td>Is Mixtral based on the idea of a mixture of e...</td>\n",
       "      <td>Based on the provided responses, the best resp...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.636265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.795422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>8f2ee9a4-72d8-4956-8131-fa0ed9bce4a0</td>\n",
       "      <td>What is sliding window attention?</td>\n",
       "      <td>The response from the first model provides the...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.691174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mixture-rag-claude-3-haiku-thought</td>\n",
       "      <td>584e89e1-cc11-4101-8c96-f10cb725fa15</td>\n",
       "      <td>How many stages are there in the development o...</td>\n",
       "      <td>The response from the second model provides th...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      experiment_name                              trace_id  \\\n",
       "0  mixture-rag-claude-3-haiku-thought  5d7ae2d3-f2b8-4840-b877-69165f991599   \n",
       "1  mixture-rag-claude-3-haiku-thought  aa2067f5-33f7-4d70-b4c9-f1752084c8ae   \n",
       "2  mixture-rag-claude-3-haiku-thought  cefa79c4-cba0-4961-bc87-005e2c2b8837   \n",
       "3  mixture-rag-claude-3-haiku-thought  8f2ee9a4-72d8-4956-8131-fa0ed9bce4a0   \n",
       "4  mixture-rag-claude-3-haiku-thought  584e89e1-cc11-4101-8c96-f10cb725fa15   \n",
       "\n",
       "                                            question  \\\n",
       "0  How can attention be described in the Transfor...   \n",
       "1                         What is Mixture of Agents?   \n",
       "2  Is Mixtral based on the idea of a mixture of e...   \n",
       "3                  What is sliding window attention?   \n",
       "4  How many stages are there in the development o...   \n",
       "\n",
       "                                              answer  faithfulness  \\\n",
       "0  The response from the second model provides th...      0.727273   \n",
       "1  The response from the third model provides the...      0.555556   \n",
       "2  Based on the provided responses, the best resp...      0.750000   \n",
       "3  The response from the first model provides the...      0.571429   \n",
       "4  The response from the second model provides th...      1.000000   \n",
       "\n",
       "   answer_relevancy  context_utilization     score  \n",
       "0          0.723033             1.000000  0.816768  \n",
       "1          0.466129             0.805556  0.609080  \n",
       "2          0.636265             1.000000  0.795422  \n",
       "3          0.691174             1.000000  0.754201  \n",
       "4          0.938562             1.000000  0.979521  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the new dataframe\n",
    "dataframe_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe by grouping the dataframe by question and calculating the mean of the scores for each question\n",
    "dataframe_2_mean = (\n",
    "    dataframe_2.drop(columns=[\"trace_id\", \"answer\", \"experiment_name\"])\n",
    "    .groupby(\"question\")\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_utilization</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>How many stages are there in the development of the Llama 3 model?</th>\n",
       "      <td>0.922808</td>\n",
       "      <td>0.894326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Does Claude 3 models have vision capabilities?</th>\n",
       "      <td>0.937603</td>\n",
       "      <td>0.973932</td>\n",
       "      <td>0.866071</td>\n",
       "      <td>0.925869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Can the GPT-4 model accept both text and image inputs?</th>\n",
       "      <td>0.862446</td>\n",
       "      <td>0.917552</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.884999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>On what architecture the Gemma model is based on?</th>\n",
       "      <td>0.602325</td>\n",
       "      <td>0.984635</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is the difference between the Llama 2 and Llama 2-Chat ?</th>\n",
       "      <td>0.813390</td>\n",
       "      <td>0.946063</td>\n",
       "      <td>0.814484</td>\n",
       "      <td>0.857979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is Mixtral based on the idea of a mixture of experts?</th>\n",
       "      <td>0.877241</td>\n",
       "      <td>0.688604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How many stages of training are in the GPT model?</th>\n",
       "      <td>0.805057</td>\n",
       "      <td>0.739909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What tokenizer is used in the Gemma2 model?</th>\n",
       "      <td>0.886317</td>\n",
       "      <td>0.970879</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.785732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is Mixture of Agents?</th>\n",
       "      <td>0.858851</td>\n",
       "      <td>0.587887</td>\n",
       "      <td>0.865079</td>\n",
       "      <td>0.770606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What are the two tasks in BERT?</th>\n",
       "      <td>0.656663</td>\n",
       "      <td>0.936283</td>\n",
       "      <td>0.712302</td>\n",
       "      <td>0.768416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How can attention be described in the Transformer?</th>\n",
       "      <td>0.685080</td>\n",
       "      <td>0.722952</td>\n",
       "      <td>0.823413</td>\n",
       "      <td>0.743815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is sliding window attention?</th>\n",
       "      <td>0.636389</td>\n",
       "      <td>0.641580</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.741466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is optimizer is used for LLaMA?</th>\n",
       "      <td>0.765981</td>\n",
       "      <td>0.830720</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.643345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>On what architecture the GPT-3 model is based on?</th>\n",
       "      <td>0.666507</td>\n",
       "      <td>0.780471</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.583516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    faithfulness  \\\n",
       "question                                                           \n",
       "How many stages are there in the development of...      0.922808   \n",
       "Does Claude 3 models have vision capabilities?          0.937603   \n",
       "Can the GPT-4 model accept both text and image ...      0.862446   \n",
       "On what architecture the Gemma model is based on?       0.602325   \n",
       "What is the difference between the Llama 2 and ...      0.813390   \n",
       "Is Mixtral based on the idea of a mixture of ex...      0.877241   \n",
       "How many stages of training are in the GPT model?       0.805057   \n",
       "What tokenizer is used in the Gemma2 model?             0.886317   \n",
       "What is Mixture of Agents?                              0.858851   \n",
       "What are the two tasks in BERT?                         0.656663   \n",
       "How can attention be described in the Transformer?      0.685080   \n",
       "What is sliding window attention?                       0.636389   \n",
       "What is optimizer is used for LLaMA?                    0.765981   \n",
       "On what architecture the GPT-3 model is based on?       0.666507   \n",
       "\n",
       "                                                    answer_relevancy  \\\n",
       "question                                                               \n",
       "How many stages are there in the development of...          0.894326   \n",
       "Does Claude 3 models have vision capabilities?              0.973932   \n",
       "Can the GPT-4 model accept both text and image ...          0.917552   \n",
       "On what architecture the Gemma model is based on?           0.984635   \n",
       "What is the difference between the Llama 2 and ...          0.946063   \n",
       "Is Mixtral based on the idea of a mixture of ex...          0.688604   \n",
       "How many stages of training are in the GPT model?           0.739909   \n",
       "What tokenizer is used in the Gemma2 model?                 0.970879   \n",
       "What is Mixture of Agents?                                  0.587887   \n",
       "What are the two tasks in BERT?                             0.936283   \n",
       "How can attention be described in the Transformer?          0.722952   \n",
       "What is sliding window attention?                           0.641580   \n",
       "What is optimizer is used for LLaMA?                        0.830720   \n",
       "On what architecture the GPT-3 model is based on?           0.780471   \n",
       "\n",
       "                                                    context_utilization  \\\n",
       "question                                                                  \n",
       "How many stages are there in the development of...             1.000000   \n",
       "Does Claude 3 models have vision capabilities?                 0.866071   \n",
       "Can the GPT-4 model accept both text and image ...             0.875000   \n",
       "On what architecture the Gemma model is based on?              1.000000   \n",
       "What is the difference between the Llama 2 and ...             0.814484   \n",
       "Is Mixtral based on the idea of a mixture of ex...             1.000000   \n",
       "How many stages of training are in the GPT model?              1.000000   \n",
       "What tokenizer is used in the Gemma2 model?                    0.500000   \n",
       "What is Mixture of Agents?                                     0.865079   \n",
       "What are the two tasks in BERT?                                0.712302   \n",
       "How can attention be described in the Transformer?             0.823413   \n",
       "What is sliding window attention?                              0.946429   \n",
       "What is optimizer is used for LLaMA?                           0.333333   \n",
       "On what architecture the GPT-3 model is based on?              0.303571   \n",
       "\n",
       "                                                       score  \n",
       "question                                                      \n",
       "How many stages are there in the development of...  0.939045  \n",
       "Does Claude 3 models have vision capabilities?      0.925869  \n",
       "Can the GPT-4 model accept both text and image ...  0.884999  \n",
       "On what architecture the Gemma model is based on?   0.862320  \n",
       "What is the difference between the Llama 2 and ...  0.857979  \n",
       "Is Mixtral based on the idea of a mixture of ex...  0.855282  \n",
       "How many stages of training are in the GPT model?   0.848322  \n",
       "What tokenizer is used in the Gemma2 model?         0.785732  \n",
       "What is Mixture of Agents?                          0.770606  \n",
       "What are the two tasks in BERT?                     0.768416  \n",
       "How can attention be described in the Transformer?  0.743815  \n",
       "What is sliding window attention?                   0.741466  \n",
       "What is optimizer is used for LLaMA?                0.643345  \n",
       "On what architecture the GPT-3 model is based on?   0.583516  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the dataframe sorted by score by descending order\n",
    "dataframe_2_mean.sort_values(by=\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of the dataframe\n",
    "dataframe_3 = dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the dataframe, excluding the questions that are not relevant for the analysis\n",
    "questions_to_exclude = [\n",
    "    \"What is optimizer is used for LLaMA?\",\n",
    "    \"On what architecture the GPT-3 model is based on?\",\n",
    "    \"What is sliding window attention?\",\n",
    "    \"How can attention be described in the Transformer?\",\n",
    "]\n",
    "\n",
    "dataframe_3_filtered = dataframe_3[~dataframe_3[\"question\"].isin(questions_to_exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with mean values for the scores for each experiment\n",
    "dataframe_3_mean = (\n",
    "    dataframe_3_filtered.drop(columns=[\"trace_id\", \"question\", \"answer\"])\n",
    "    .groupby(\"experiment_name\")\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a score for each row by calculating the mean of the scores for each row (faithfulness, answer_relevancy, context_utilization)\n",
    "dataframe_3_mean[\"score\"] = dataframe_3_mean[\n",
    "    [\"faithfulness\", \"answer_relevancy\", \"context_utilization\"]\n",
    "].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_utilization</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-70b-instruct</th>\n",
       "      <td>0.961231</td>\n",
       "      <td>0.844946</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.890022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-8b</th>\n",
       "      <td>0.957778</td>\n",
       "      <td>0.822676</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.887003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-405b-instruct</th>\n",
       "      <td>0.945641</td>\n",
       "      <td>0.846877</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.896580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-thought</th>\n",
       "      <td>0.924542</td>\n",
       "      <td>0.910476</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.905191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma-7b-it</th>\n",
       "      <td>0.923677</td>\n",
       "      <td>0.863669</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.887449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-8b</th>\n",
       "      <td>0.913214</td>\n",
       "      <td>0.856165</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.881460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-70b</th>\n",
       "      <td>0.901136</td>\n",
       "      <td>0.885328</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.883451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mixtral-8x7b-instruct</th>\n",
       "      <td>0.896447</td>\n",
       "      <td>0.884369</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.896383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o</th>\n",
       "      <td>0.895355</td>\n",
       "      <td>0.884128</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.892235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-thought</th>\n",
       "      <td>0.892727</td>\n",
       "      <td>0.794075</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.840045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-modified</th>\n",
       "      <td>0.882197</td>\n",
       "      <td>0.859517</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.886127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mistral-7b-instruct</th>\n",
       "      <td>0.878027</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.900319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-opus</th>\n",
       "      <td>0.867106</td>\n",
       "      <td>0.891054</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.843461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o-mini</th>\n",
       "      <td>0.851786</td>\n",
       "      <td>0.918347</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.890044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma2-9b-it</th>\n",
       "      <td>0.846212</td>\n",
       "      <td>0.905305</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.871802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-modified</th>\n",
       "      <td>0.825208</td>\n",
       "      <td>0.867729</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.857831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3.5-sonnet</th>\n",
       "      <td>0.821840</td>\n",
       "      <td>0.905330</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.850723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-thought</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.897726</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.852205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4-turbo</th>\n",
       "      <td>0.818758</td>\n",
       "      <td>0.860509</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.833829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-sonnet</th>\n",
       "      <td>0.817931</td>\n",
       "      <td>0.874334</td>\n",
       "      <td>0.813889</td>\n",
       "      <td>0.835385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-haiku</th>\n",
       "      <td>0.777341</td>\n",
       "      <td>0.865661</td>\n",
       "      <td>0.830556</td>\n",
       "      <td>0.824519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct</th>\n",
       "      <td>0.745750</td>\n",
       "      <td>0.845767</td>\n",
       "      <td>0.913889</td>\n",
       "      <td>0.835136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct</th>\n",
       "      <td>0.735352</td>\n",
       "      <td>0.806652</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.819557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-modified</th>\n",
       "      <td>0.709821</td>\n",
       "      <td>0.871686</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.826243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it</th>\n",
       "      <td>0.643156</td>\n",
       "      <td>0.861826</td>\n",
       "      <td>0.852778</td>\n",
       "      <td>0.785920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku</th>\n",
       "      <td>0.594921</td>\n",
       "      <td>0.844030</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>0.770391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-thought</th>\n",
       "      <td>0.592778</td>\n",
       "      <td>0.747040</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.701235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-modified</th>\n",
       "      <td>0.583637</td>\n",
       "      <td>0.862378</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.751449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           faithfulness  answer_relevancy  \\\n",
       "experiment_name                                                             \n",
       "simple-rag-llama-3.1-70b-instruct              0.961231          0.844946   \n",
       "simple-rag-llama-3.1-8b                        0.957778          0.822676   \n",
       "simple-rag-llama-3.1-405b-instruct             0.945641          0.846877   \n",
       "mixture-rag-gemma2-9b-it-thought               0.924542          0.910476   \n",
       "simple-rag-gemma-7b-it                         0.923677          0.863669   \n",
       "simple-rag-llama-3-8b                          0.913214          0.856165   \n",
       "simple-rag-llama-3-70b                         0.901136          0.885328   \n",
       "simple-rag-mixtral-8x7b-instruct               0.896447          0.884369   \n",
       "simple-rag-gpt-4o                              0.895355          0.884128   \n",
       "mixture-rag-mixtral-8x7-instruct-thought       0.892727          0.794075   \n",
       "mixture-rag-mixtral-8x7-instruct-modified      0.882197          0.859517   \n",
       "simple-rag-mistral-7b-instruct                 0.878027          0.914597   \n",
       "simple-rag-claude-3-opus                       0.867106          0.891054   \n",
       "simple-rag-gpt-4o-mini                         0.851786          0.918347   \n",
       "simple-rag-gemma2-9b-it                        0.846212          0.905305   \n",
       "mixture-rag-gemma2-9b-it-modified              0.825208          0.867729   \n",
       "simple-rag-claude-3.5-sonnet                   0.821840          0.905330   \n",
       "mixture-rag-llama3.1-8b-instruct-thought       0.820000          0.897726   \n",
       "simple-rag-gpt-4-turbo                         0.818758          0.860509   \n",
       "simple-rag-claude-3-sonnet                     0.817931          0.874334   \n",
       "simple-rag-claude-3-haiku                      0.777341          0.865661   \n",
       "mixture-rag-mixtral-8x7-instruct               0.745750          0.845767   \n",
       "mixture-rag-llama3.1-8b-instruct               0.735352          0.806652   \n",
       "mixture-rag-llama3.1-8b-instruct-modified      0.709821          0.871686   \n",
       "mixture-rag-gemma2-9b-it                       0.643156          0.861826   \n",
       "mixture-rag-claude-3-haiku                     0.594921          0.844030   \n",
       "mixture-rag-claude-3-haiku-thought             0.592778          0.747040   \n",
       "mixture-rag-claude-3-haiku-modified            0.583637          0.862378   \n",
       "\n",
       "                                           context_utilization     score  \n",
       "experiment_name                                                           \n",
       "simple-rag-llama-3.1-70b-instruct                     0.863889  0.890022  \n",
       "simple-rag-llama-3.1-8b                               0.880556  0.887003  \n",
       "simple-rag-llama-3.1-405b-instruct                    0.897222  0.896580  \n",
       "mixture-rag-gemma2-9b-it-thought                      0.880556  0.905191  \n",
       "simple-rag-gemma-7b-it                                0.875000  0.887449  \n",
       "simple-rag-llama-3-8b                                 0.875000  0.881460  \n",
       "simple-rag-llama-3-70b                                0.863889  0.883451  \n",
       "simple-rag-mixtral-8x7b-instruct                      0.908333  0.896383  \n",
       "simple-rag-gpt-4o                                     0.897222  0.892235  \n",
       "mixture-rag-mixtral-8x7-instruct-thought              0.833333  0.840045  \n",
       "mixture-rag-mixtral-8x7-instruct-modified             0.916667  0.886127  \n",
       "simple-rag-mistral-7b-instruct                        0.908333  0.900319  \n",
       "simple-rag-claude-3-opus                              0.772222  0.843461  \n",
       "simple-rag-gpt-4o-mini                                0.900000  0.890044  \n",
       "simple-rag-gemma2-9b-it                               0.863889  0.871802  \n",
       "mixture-rag-gemma2-9b-it-modified                     0.880556  0.857831  \n",
       "simple-rag-claude-3.5-sonnet                          0.825000  0.850723  \n",
       "mixture-rag-llama3.1-8b-instruct-thought              0.838889  0.852205  \n",
       "simple-rag-gpt-4-turbo                                0.822222  0.833829  \n",
       "simple-rag-claude-3-sonnet                            0.813889  0.835385  \n",
       "simple-rag-claude-3-haiku                             0.830556  0.824519  \n",
       "mixture-rag-mixtral-8x7-instruct                      0.913889  0.835136  \n",
       "mixture-rag-llama3.1-8b-instruct                      0.916667  0.819557  \n",
       "mixture-rag-llama3.1-8b-instruct-modified             0.897222  0.826243  \n",
       "mixture-rag-gemma2-9b-it                              0.852778  0.785920  \n",
       "mixture-rag-claude-3-haiku                            0.872222  0.770391  \n",
       "mixture-rag-claude-3-haiku-thought                    0.763889  0.701235  \n",
       "mixture-rag-claude-3-haiku-modified                   0.808333  0.751449  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the dataframe sorted by faithfulness by descending order\n",
    "dataframe_3_mean.sort_values(by=\"faithfulness\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_utilization</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o-mini</th>\n",
       "      <td>0.851786</td>\n",
       "      <td>0.918347</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.890044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mistral-7b-instruct</th>\n",
       "      <td>0.878027</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.900319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-thought</th>\n",
       "      <td>0.924542</td>\n",
       "      <td>0.910476</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.905191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3.5-sonnet</th>\n",
       "      <td>0.821840</td>\n",
       "      <td>0.905330</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.850723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma2-9b-it</th>\n",
       "      <td>0.846212</td>\n",
       "      <td>0.905305</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.871802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-thought</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.897726</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.852205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-opus</th>\n",
       "      <td>0.867106</td>\n",
       "      <td>0.891054</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.843461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-70b</th>\n",
       "      <td>0.901136</td>\n",
       "      <td>0.885328</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.883451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mixtral-8x7b-instruct</th>\n",
       "      <td>0.896447</td>\n",
       "      <td>0.884369</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.896383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o</th>\n",
       "      <td>0.895355</td>\n",
       "      <td>0.884128</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.892235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-sonnet</th>\n",
       "      <td>0.817931</td>\n",
       "      <td>0.874334</td>\n",
       "      <td>0.813889</td>\n",
       "      <td>0.835385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-modified</th>\n",
       "      <td>0.709821</td>\n",
       "      <td>0.871686</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.826243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-modified</th>\n",
       "      <td>0.825208</td>\n",
       "      <td>0.867729</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.857831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-haiku</th>\n",
       "      <td>0.777341</td>\n",
       "      <td>0.865661</td>\n",
       "      <td>0.830556</td>\n",
       "      <td>0.824519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma-7b-it</th>\n",
       "      <td>0.923677</td>\n",
       "      <td>0.863669</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.887449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-modified</th>\n",
       "      <td>0.583637</td>\n",
       "      <td>0.862378</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.751449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it</th>\n",
       "      <td>0.643156</td>\n",
       "      <td>0.861826</td>\n",
       "      <td>0.852778</td>\n",
       "      <td>0.785920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4-turbo</th>\n",
       "      <td>0.818758</td>\n",
       "      <td>0.860509</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.833829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-modified</th>\n",
       "      <td>0.882197</td>\n",
       "      <td>0.859517</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.886127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-8b</th>\n",
       "      <td>0.913214</td>\n",
       "      <td>0.856165</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.881460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-405b-instruct</th>\n",
       "      <td>0.945641</td>\n",
       "      <td>0.846877</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.896580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct</th>\n",
       "      <td>0.745750</td>\n",
       "      <td>0.845767</td>\n",
       "      <td>0.913889</td>\n",
       "      <td>0.835136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-70b-instruct</th>\n",
       "      <td>0.961231</td>\n",
       "      <td>0.844946</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.890022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku</th>\n",
       "      <td>0.594921</td>\n",
       "      <td>0.844030</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>0.770391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-8b</th>\n",
       "      <td>0.957778</td>\n",
       "      <td>0.822676</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.887003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct</th>\n",
       "      <td>0.735352</td>\n",
       "      <td>0.806652</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.819557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-thought</th>\n",
       "      <td>0.892727</td>\n",
       "      <td>0.794075</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.840045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-thought</th>\n",
       "      <td>0.592778</td>\n",
       "      <td>0.747040</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.701235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           faithfulness  answer_relevancy  \\\n",
       "experiment_name                                                             \n",
       "simple-rag-gpt-4o-mini                         0.851786          0.918347   \n",
       "simple-rag-mistral-7b-instruct                 0.878027          0.914597   \n",
       "mixture-rag-gemma2-9b-it-thought               0.924542          0.910476   \n",
       "simple-rag-claude-3.5-sonnet                   0.821840          0.905330   \n",
       "simple-rag-gemma2-9b-it                        0.846212          0.905305   \n",
       "mixture-rag-llama3.1-8b-instruct-thought       0.820000          0.897726   \n",
       "simple-rag-claude-3-opus                       0.867106          0.891054   \n",
       "simple-rag-llama-3-70b                         0.901136          0.885328   \n",
       "simple-rag-mixtral-8x7b-instruct               0.896447          0.884369   \n",
       "simple-rag-gpt-4o                              0.895355          0.884128   \n",
       "simple-rag-claude-3-sonnet                     0.817931          0.874334   \n",
       "mixture-rag-llama3.1-8b-instruct-modified      0.709821          0.871686   \n",
       "mixture-rag-gemma2-9b-it-modified              0.825208          0.867729   \n",
       "simple-rag-claude-3-haiku                      0.777341          0.865661   \n",
       "simple-rag-gemma-7b-it                         0.923677          0.863669   \n",
       "mixture-rag-claude-3-haiku-modified            0.583637          0.862378   \n",
       "mixture-rag-gemma2-9b-it                       0.643156          0.861826   \n",
       "simple-rag-gpt-4-turbo                         0.818758          0.860509   \n",
       "mixture-rag-mixtral-8x7-instruct-modified      0.882197          0.859517   \n",
       "simple-rag-llama-3-8b                          0.913214          0.856165   \n",
       "simple-rag-llama-3.1-405b-instruct             0.945641          0.846877   \n",
       "mixture-rag-mixtral-8x7-instruct               0.745750          0.845767   \n",
       "simple-rag-llama-3.1-70b-instruct              0.961231          0.844946   \n",
       "mixture-rag-claude-3-haiku                     0.594921          0.844030   \n",
       "simple-rag-llama-3.1-8b                        0.957778          0.822676   \n",
       "mixture-rag-llama3.1-8b-instruct               0.735352          0.806652   \n",
       "mixture-rag-mixtral-8x7-instruct-thought       0.892727          0.794075   \n",
       "mixture-rag-claude-3-haiku-thought             0.592778          0.747040   \n",
       "\n",
       "                                           context_utilization     score  \n",
       "experiment_name                                                           \n",
       "simple-rag-gpt-4o-mini                                0.900000  0.890044  \n",
       "simple-rag-mistral-7b-instruct                        0.908333  0.900319  \n",
       "mixture-rag-gemma2-9b-it-thought                      0.880556  0.905191  \n",
       "simple-rag-claude-3.5-sonnet                          0.825000  0.850723  \n",
       "simple-rag-gemma2-9b-it                               0.863889  0.871802  \n",
       "mixture-rag-llama3.1-8b-instruct-thought              0.838889  0.852205  \n",
       "simple-rag-claude-3-opus                              0.772222  0.843461  \n",
       "simple-rag-llama-3-70b                                0.863889  0.883451  \n",
       "simple-rag-mixtral-8x7b-instruct                      0.908333  0.896383  \n",
       "simple-rag-gpt-4o                                     0.897222  0.892235  \n",
       "simple-rag-claude-3-sonnet                            0.813889  0.835385  \n",
       "mixture-rag-llama3.1-8b-instruct-modified             0.897222  0.826243  \n",
       "mixture-rag-gemma2-9b-it-modified                     0.880556  0.857831  \n",
       "simple-rag-claude-3-haiku                             0.830556  0.824519  \n",
       "simple-rag-gemma-7b-it                                0.875000  0.887449  \n",
       "mixture-rag-claude-3-haiku-modified                   0.808333  0.751449  \n",
       "mixture-rag-gemma2-9b-it                              0.852778  0.785920  \n",
       "simple-rag-gpt-4-turbo                                0.822222  0.833829  \n",
       "mixture-rag-mixtral-8x7-instruct-modified             0.916667  0.886127  \n",
       "simple-rag-llama-3-8b                                 0.875000  0.881460  \n",
       "simple-rag-llama-3.1-405b-instruct                    0.897222  0.896580  \n",
       "mixture-rag-mixtral-8x7-instruct                      0.913889  0.835136  \n",
       "simple-rag-llama-3.1-70b-instruct                     0.863889  0.890022  \n",
       "mixture-rag-claude-3-haiku                            0.872222  0.770391  \n",
       "simple-rag-llama-3.1-8b                               0.880556  0.887003  \n",
       "mixture-rag-llama3.1-8b-instruct                      0.916667  0.819557  \n",
       "mixture-rag-mixtral-8x7-instruct-thought              0.833333  0.840045  \n",
       "mixture-rag-claude-3-haiku-thought                    0.763889  0.701235  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the dataframe sorted by answer_relevancy by descending order\n",
    "dataframe_3_mean.sort_values(by=\"answer_relevancy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_utilization</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct</th>\n",
       "      <td>0.735352</td>\n",
       "      <td>0.806652</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.819557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-modified</th>\n",
       "      <td>0.882197</td>\n",
       "      <td>0.859517</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.886127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct</th>\n",
       "      <td>0.745750</td>\n",
       "      <td>0.845767</td>\n",
       "      <td>0.913889</td>\n",
       "      <td>0.835136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mixtral-8x7b-instruct</th>\n",
       "      <td>0.896447</td>\n",
       "      <td>0.884369</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.896383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mistral-7b-instruct</th>\n",
       "      <td>0.878027</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.900319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o-mini</th>\n",
       "      <td>0.851786</td>\n",
       "      <td>0.918347</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.890044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-modified</th>\n",
       "      <td>0.709821</td>\n",
       "      <td>0.871686</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.826243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-405b-instruct</th>\n",
       "      <td>0.945641</td>\n",
       "      <td>0.846877</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.896580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o</th>\n",
       "      <td>0.895355</td>\n",
       "      <td>0.884128</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.892235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-modified</th>\n",
       "      <td>0.825208</td>\n",
       "      <td>0.867729</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.857831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-thought</th>\n",
       "      <td>0.924542</td>\n",
       "      <td>0.910476</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.905191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-8b</th>\n",
       "      <td>0.957778</td>\n",
       "      <td>0.822676</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.887003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma-7b-it</th>\n",
       "      <td>0.923677</td>\n",
       "      <td>0.863669</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.887449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-8b</th>\n",
       "      <td>0.913214</td>\n",
       "      <td>0.856165</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.881460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku</th>\n",
       "      <td>0.594921</td>\n",
       "      <td>0.844030</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>0.770391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-70b</th>\n",
       "      <td>0.901136</td>\n",
       "      <td>0.885328</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.883451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma2-9b-it</th>\n",
       "      <td>0.846212</td>\n",
       "      <td>0.905305</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.871802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-70b-instruct</th>\n",
       "      <td>0.961231</td>\n",
       "      <td>0.844946</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.890022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it</th>\n",
       "      <td>0.643156</td>\n",
       "      <td>0.861826</td>\n",
       "      <td>0.852778</td>\n",
       "      <td>0.785920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-thought</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.897726</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.852205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-thought</th>\n",
       "      <td>0.892727</td>\n",
       "      <td>0.794075</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.840045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-haiku</th>\n",
       "      <td>0.777341</td>\n",
       "      <td>0.865661</td>\n",
       "      <td>0.830556</td>\n",
       "      <td>0.824519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3.5-sonnet</th>\n",
       "      <td>0.821840</td>\n",
       "      <td>0.905330</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.850723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4-turbo</th>\n",
       "      <td>0.818758</td>\n",
       "      <td>0.860509</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.833829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-sonnet</th>\n",
       "      <td>0.817931</td>\n",
       "      <td>0.874334</td>\n",
       "      <td>0.813889</td>\n",
       "      <td>0.835385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-modified</th>\n",
       "      <td>0.583637</td>\n",
       "      <td>0.862378</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.751449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-opus</th>\n",
       "      <td>0.867106</td>\n",
       "      <td>0.891054</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.843461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-thought</th>\n",
       "      <td>0.592778</td>\n",
       "      <td>0.747040</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.701235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           faithfulness  answer_relevancy  \\\n",
       "experiment_name                                                             \n",
       "mixture-rag-llama3.1-8b-instruct               0.735352          0.806652   \n",
       "mixture-rag-mixtral-8x7-instruct-modified      0.882197          0.859517   \n",
       "mixture-rag-mixtral-8x7-instruct               0.745750          0.845767   \n",
       "simple-rag-mixtral-8x7b-instruct               0.896447          0.884369   \n",
       "simple-rag-mistral-7b-instruct                 0.878027          0.914597   \n",
       "simple-rag-gpt-4o-mini                         0.851786          0.918347   \n",
       "mixture-rag-llama3.1-8b-instruct-modified      0.709821          0.871686   \n",
       "simple-rag-llama-3.1-405b-instruct             0.945641          0.846877   \n",
       "simple-rag-gpt-4o                              0.895355          0.884128   \n",
       "mixture-rag-gemma2-9b-it-modified              0.825208          0.867729   \n",
       "mixture-rag-gemma2-9b-it-thought               0.924542          0.910476   \n",
       "simple-rag-llama-3.1-8b                        0.957778          0.822676   \n",
       "simple-rag-gemma-7b-it                         0.923677          0.863669   \n",
       "simple-rag-llama-3-8b                          0.913214          0.856165   \n",
       "mixture-rag-claude-3-haiku                     0.594921          0.844030   \n",
       "simple-rag-llama-3-70b                         0.901136          0.885328   \n",
       "simple-rag-gemma2-9b-it                        0.846212          0.905305   \n",
       "simple-rag-llama-3.1-70b-instruct              0.961231          0.844946   \n",
       "mixture-rag-gemma2-9b-it                       0.643156          0.861826   \n",
       "mixture-rag-llama3.1-8b-instruct-thought       0.820000          0.897726   \n",
       "mixture-rag-mixtral-8x7-instruct-thought       0.892727          0.794075   \n",
       "simple-rag-claude-3-haiku                      0.777341          0.865661   \n",
       "simple-rag-claude-3.5-sonnet                   0.821840          0.905330   \n",
       "simple-rag-gpt-4-turbo                         0.818758          0.860509   \n",
       "simple-rag-claude-3-sonnet                     0.817931          0.874334   \n",
       "mixture-rag-claude-3-haiku-modified            0.583637          0.862378   \n",
       "simple-rag-claude-3-opus                       0.867106          0.891054   \n",
       "mixture-rag-claude-3-haiku-thought             0.592778          0.747040   \n",
       "\n",
       "                                           context_utilization     score  \n",
       "experiment_name                                                           \n",
       "mixture-rag-llama3.1-8b-instruct                      0.916667  0.819557  \n",
       "mixture-rag-mixtral-8x7-instruct-modified             0.916667  0.886127  \n",
       "mixture-rag-mixtral-8x7-instruct                      0.913889  0.835136  \n",
       "simple-rag-mixtral-8x7b-instruct                      0.908333  0.896383  \n",
       "simple-rag-mistral-7b-instruct                        0.908333  0.900319  \n",
       "simple-rag-gpt-4o-mini                                0.900000  0.890044  \n",
       "mixture-rag-llama3.1-8b-instruct-modified             0.897222  0.826243  \n",
       "simple-rag-llama-3.1-405b-instruct                    0.897222  0.896580  \n",
       "simple-rag-gpt-4o                                     0.897222  0.892235  \n",
       "mixture-rag-gemma2-9b-it-modified                     0.880556  0.857831  \n",
       "mixture-rag-gemma2-9b-it-thought                      0.880556  0.905191  \n",
       "simple-rag-llama-3.1-8b                               0.880556  0.887003  \n",
       "simple-rag-gemma-7b-it                                0.875000  0.887449  \n",
       "simple-rag-llama-3-8b                                 0.875000  0.881460  \n",
       "mixture-rag-claude-3-haiku                            0.872222  0.770391  \n",
       "simple-rag-llama-3-70b                                0.863889  0.883451  \n",
       "simple-rag-gemma2-9b-it                               0.863889  0.871802  \n",
       "simple-rag-llama-3.1-70b-instruct                     0.863889  0.890022  \n",
       "mixture-rag-gemma2-9b-it                              0.852778  0.785920  \n",
       "mixture-rag-llama3.1-8b-instruct-thought              0.838889  0.852205  \n",
       "mixture-rag-mixtral-8x7-instruct-thought              0.833333  0.840045  \n",
       "simple-rag-claude-3-haiku                             0.830556  0.824519  \n",
       "simple-rag-claude-3.5-sonnet                          0.825000  0.850723  \n",
       "simple-rag-gpt-4-turbo                                0.822222  0.833829  \n",
       "simple-rag-claude-3-sonnet                            0.813889  0.835385  \n",
       "mixture-rag-claude-3-haiku-modified                   0.808333  0.751449  \n",
       "simple-rag-claude-3-opus                              0.772222  0.843461  \n",
       "mixture-rag-claude-3-haiku-thought                    0.763889  0.701235  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the dataframe sorted by context_utilization by descending order\n",
    "dataframe_3_mean.sort_values(by=\"context_utilization\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_utilization</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-thought</th>\n",
       "      <td>0.924542</td>\n",
       "      <td>0.910476</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.905191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mistral-7b-instruct</th>\n",
       "      <td>0.878027</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.900319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-405b-instruct</th>\n",
       "      <td>0.945641</td>\n",
       "      <td>0.846877</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.896580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-mixtral-8x7b-instruct</th>\n",
       "      <td>0.896447</td>\n",
       "      <td>0.884369</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.896383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o</th>\n",
       "      <td>0.895355</td>\n",
       "      <td>0.884128</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.892235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4o-mini</th>\n",
       "      <td>0.851786</td>\n",
       "      <td>0.918347</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.890044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-70b-instruct</th>\n",
       "      <td>0.961231</td>\n",
       "      <td>0.844946</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.890022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma-7b-it</th>\n",
       "      <td>0.923677</td>\n",
       "      <td>0.863669</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.887449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3.1-8b</th>\n",
       "      <td>0.957778</td>\n",
       "      <td>0.822676</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.887003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-modified</th>\n",
       "      <td>0.882197</td>\n",
       "      <td>0.859517</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.886127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-70b</th>\n",
       "      <td>0.901136</td>\n",
       "      <td>0.885328</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.883451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-llama-3-8b</th>\n",
       "      <td>0.913214</td>\n",
       "      <td>0.856165</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.881460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gemma2-9b-it</th>\n",
       "      <td>0.846212</td>\n",
       "      <td>0.905305</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.871802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it-modified</th>\n",
       "      <td>0.825208</td>\n",
       "      <td>0.867729</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.857831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-thought</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.897726</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.852205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3.5-sonnet</th>\n",
       "      <td>0.821840</td>\n",
       "      <td>0.905330</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.850723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-opus</th>\n",
       "      <td>0.867106</td>\n",
       "      <td>0.891054</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.843461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct-thought</th>\n",
       "      <td>0.892727</td>\n",
       "      <td>0.794075</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.840045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-sonnet</th>\n",
       "      <td>0.817931</td>\n",
       "      <td>0.874334</td>\n",
       "      <td>0.813889</td>\n",
       "      <td>0.835385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-mixtral-8x7-instruct</th>\n",
       "      <td>0.745750</td>\n",
       "      <td>0.845767</td>\n",
       "      <td>0.913889</td>\n",
       "      <td>0.835136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-gpt-4-turbo</th>\n",
       "      <td>0.818758</td>\n",
       "      <td>0.860509</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.833829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct-modified</th>\n",
       "      <td>0.709821</td>\n",
       "      <td>0.871686</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.826243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple-rag-claude-3-haiku</th>\n",
       "      <td>0.777341</td>\n",
       "      <td>0.865661</td>\n",
       "      <td>0.830556</td>\n",
       "      <td>0.824519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-llama3.1-8b-instruct</th>\n",
       "      <td>0.735352</td>\n",
       "      <td>0.806652</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.819557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-gemma2-9b-it</th>\n",
       "      <td>0.643156</td>\n",
       "      <td>0.861826</td>\n",
       "      <td>0.852778</td>\n",
       "      <td>0.785920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku</th>\n",
       "      <td>0.594921</td>\n",
       "      <td>0.844030</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>0.770391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-modified</th>\n",
       "      <td>0.583637</td>\n",
       "      <td>0.862378</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.751449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture-rag-claude-3-haiku-thought</th>\n",
       "      <td>0.592778</td>\n",
       "      <td>0.747040</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.701235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           faithfulness  answer_relevancy  \\\n",
       "experiment_name                                                             \n",
       "mixture-rag-gemma2-9b-it-thought               0.924542          0.910476   \n",
       "simple-rag-mistral-7b-instruct                 0.878027          0.914597   \n",
       "simple-rag-llama-3.1-405b-instruct             0.945641          0.846877   \n",
       "simple-rag-mixtral-8x7b-instruct               0.896447          0.884369   \n",
       "simple-rag-gpt-4o                              0.895355          0.884128   \n",
       "simple-rag-gpt-4o-mini                         0.851786          0.918347   \n",
       "simple-rag-llama-3.1-70b-instruct              0.961231          0.844946   \n",
       "simple-rag-gemma-7b-it                         0.923677          0.863669   \n",
       "simple-rag-llama-3.1-8b                        0.957778          0.822676   \n",
       "mixture-rag-mixtral-8x7-instruct-modified      0.882197          0.859517   \n",
       "simple-rag-llama-3-70b                         0.901136          0.885328   \n",
       "simple-rag-llama-3-8b                          0.913214          0.856165   \n",
       "simple-rag-gemma2-9b-it                        0.846212          0.905305   \n",
       "mixture-rag-gemma2-9b-it-modified              0.825208          0.867729   \n",
       "mixture-rag-llama3.1-8b-instruct-thought       0.820000          0.897726   \n",
       "simple-rag-claude-3.5-sonnet                   0.821840          0.905330   \n",
       "simple-rag-claude-3-opus                       0.867106          0.891054   \n",
       "mixture-rag-mixtral-8x7-instruct-thought       0.892727          0.794075   \n",
       "simple-rag-claude-3-sonnet                     0.817931          0.874334   \n",
       "mixture-rag-mixtral-8x7-instruct               0.745750          0.845767   \n",
       "simple-rag-gpt-4-turbo                         0.818758          0.860509   \n",
       "mixture-rag-llama3.1-8b-instruct-modified      0.709821          0.871686   \n",
       "simple-rag-claude-3-haiku                      0.777341          0.865661   \n",
       "mixture-rag-llama3.1-8b-instruct               0.735352          0.806652   \n",
       "mixture-rag-gemma2-9b-it                       0.643156          0.861826   \n",
       "mixture-rag-claude-3-haiku                     0.594921          0.844030   \n",
       "mixture-rag-claude-3-haiku-modified            0.583637          0.862378   \n",
       "mixture-rag-claude-3-haiku-thought             0.592778          0.747040   \n",
       "\n",
       "                                           context_utilization     score  \n",
       "experiment_name                                                           \n",
       "mixture-rag-gemma2-9b-it-thought                      0.880556  0.905191  \n",
       "simple-rag-mistral-7b-instruct                        0.908333  0.900319  \n",
       "simple-rag-llama-3.1-405b-instruct                    0.897222  0.896580  \n",
       "simple-rag-mixtral-8x7b-instruct                      0.908333  0.896383  \n",
       "simple-rag-gpt-4o                                     0.897222  0.892235  \n",
       "simple-rag-gpt-4o-mini                                0.900000  0.890044  \n",
       "simple-rag-llama-3.1-70b-instruct                     0.863889  0.890022  \n",
       "simple-rag-gemma-7b-it                                0.875000  0.887449  \n",
       "simple-rag-llama-3.1-8b                               0.880556  0.887003  \n",
       "mixture-rag-mixtral-8x7-instruct-modified             0.916667  0.886127  \n",
       "simple-rag-llama-3-70b                                0.863889  0.883451  \n",
       "simple-rag-llama-3-8b                                 0.875000  0.881460  \n",
       "simple-rag-gemma2-9b-it                               0.863889  0.871802  \n",
       "mixture-rag-gemma2-9b-it-modified                     0.880556  0.857831  \n",
       "mixture-rag-llama3.1-8b-instruct-thought              0.838889  0.852205  \n",
       "simple-rag-claude-3.5-sonnet                          0.825000  0.850723  \n",
       "simple-rag-claude-3-opus                              0.772222  0.843461  \n",
       "mixture-rag-mixtral-8x7-instruct-thought              0.833333  0.840045  \n",
       "simple-rag-claude-3-sonnet                            0.813889  0.835385  \n",
       "mixture-rag-mixtral-8x7-instruct                      0.913889  0.835136  \n",
       "simple-rag-gpt-4-turbo                                0.822222  0.833829  \n",
       "mixture-rag-llama3.1-8b-instruct-modified             0.897222  0.826243  \n",
       "simple-rag-claude-3-haiku                             0.830556  0.824519  \n",
       "mixture-rag-llama3.1-8b-instruct                      0.916667  0.819557  \n",
       "mixture-rag-gemma2-9b-it                              0.852778  0.785920  \n",
       "mixture-rag-claude-3-haiku                            0.872222  0.770391  \n",
       "mixture-rag-claude-3-haiku-modified                   0.808333  0.751449  \n",
       "mixture-rag-claude-3-haiku-thought                    0.763889  0.701235  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the dataframe sorted by score(mean of all the metric scores on experiment level) by descending order\n",
    "dataframe_3_mean.sort_values(by=\"score\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
